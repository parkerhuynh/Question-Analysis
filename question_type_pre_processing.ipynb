{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f75f0e56-ede7-4011-a41e-d1fb560dcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "570e195c-47d9-44cf-b6fe-6f63ab94edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_type_processing(question_type):\n",
    "    question_type = question_type.split(\",\")[0]\n",
    "    question_type = question_type.lower()\n",
    "    question_type = question_type.replace(\"'\", \"\")\n",
    "    question_type = question_type.replace(\".\", \"\")\n",
    "    question_type = question_type.replace(\"`\", \"\")\n",
    "    question_type = question_type.replace('\"', \"\")\n",
    "    question_type = question_type.replace(\"question type: \", \"\")\n",
    "    question_type = question_type.replace(\"question: \", \"\")\n",
    "    question_type = question_type.replace(\"â€™\", \"\")\n",
    "    question_type = question_type.replace(\"[\", \"\")\n",
    "    question_type = question_type.replace(\"]\", \"\")\n",
    "    question_type = question_type.replace(\"-\", \"\")\n",
    "    # question_type = question_type.split('(')[0].strip()\n",
    "\n",
    "    if \"object identification or animal\" in question_type or \"object identification (dog)\" in question_type or \"object identification (for the presence of a cat)\" in question_type:\n",
    "        return 'animal'\n",
    "    elif \"counting\" in question_type:\n",
    "         return 'counting'\n",
    "    elif \"sentiment\" in question_type:\n",
    "        return 'emotion and sentiment'\n",
    "    elif \"color\" in question_type:\n",
    "        return 'color'\n",
    "    elif \"texture\" in question_type or \"text\" in question_type :\n",
    "        return 'text and signage recognition'\n",
    "    elif \"material\" in question_type:\n",
    "        return 'material'\n",
    "    elif \"object recognition\" in question_type or \"appearance\" in question_type or \"object identification\" in question_type or \"transportation\" in question_type:\n",
    "        return 'object identification'\n",
    "    elif \"food\" in question_type:\n",
    "        return 'object identification'\n",
    "    # elif \"signage recognition\" in question_type:\n",
    "    #     return 'signage recognition'\n",
    "    # elif \"spatial relations\" in question_type:\n",
    "    #     return 'location and spatial relations'\n",
    "    # elif \"emoition and sentiment\" in question_type or 'emotikon and sentiment' in question_type:\n",
    "    #     return 'emotion and sentiment'\n",
    "    elif \"comparison\" in question_type or \" comparison\" in question_type:\n",
    "        return 'comparison'\n",
    "    elif \"spatial relations\" in question_type:\n",
    "        return 'location and spatial relations'\n",
    "    elif \"activity recognition\" in question_type or \"what is the train doing?\" in question_type:\n",
    "        return 'activity recognition'\n",
    "\n",
    "    elif \"person identification\" in question_type:\n",
    "        return 'person identification'\n",
    "\t\n",
    "\n",
    "    elif \"action recognition\" in question_type:\n",
    "        return 'activity recognition'\n",
    "    elif \"binary question\" in question_type:\n",
    "        return 'animal'\n",
    "    elif \"time and sequence\" in question_type:\n",
    "        return 'time and sequence'\n",
    "    \n",
    "    # if question_type not in ['object identification', 'color', 'location and spatial relations', 'counting', 'activity recognition', \n",
    "    # 'person identification', 'comparison', 'text and signage recognition', 'emotion and sentiment', 'sport identification', \n",
    "    # 'animal', 'weather', 'shape', 'time and sequence', 'material']:\n",
    "    #     return 'other'\n",
    "    return question_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f8416eb-4dd4-42a6-99da-639c3bc40bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['object identification',\n",
       " 'color',\n",
       " 'location and spatial relations',\n",
       " 'counting',\n",
       " 'activity recognition',\n",
       " 'person identification',\n",
       " 'comparison',\n",
       " 'text and signage recognition',\n",
       " 'emotion and sentiment',\n",
       " 'sport identification',\n",
       " 'animal',\n",
       " 'weather',\n",
       " 'shape',\n",
       " 'time and sequence',\n",
       " 'material']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_type_dict = {}\n",
    "with open('/home/ndhuynh/github/Question-Analysis/train_question_type_gpt.json', 'r') as file:\n",
    "    for line in file:\n",
    "        question_object = json.loads(line)\n",
    "        question_str = question_object[\"question\"]\n",
    "        question_type = question_object[\"question_type\"]\n",
    "        question_type = question_type_processing(question_type)\n",
    "        question_type_dict[question_str] = question_type\n",
    "file.close()\n",
    "with open('/home/ndhuynh/github/Question-Analysis/val_question_type_gpt.json', 'r') as file:\n",
    "    for line in file:\n",
    "        question_object = json.loads(line)\n",
    "        question_str = question_object[\"question\"]\n",
    "        if question_str not in question_type_dict:\n",
    "            question_type = question_object[\"question_type\"]\n",
    "            question_type = question_type_processing(question_type)\n",
    "            question_type_dict[question_str] = question_type\n",
    "file.close()\n",
    "with open('/home/ndhuynh/data/simpsonsvqa/v1_Question_Train_simpsons_vqa.json', 'r') as file:\n",
    "    train_questions = json.load(file)[\"questions\"]\n",
    "train_questions = pd.DataFrame(train_questions)\n",
    "with open('/home/ndhuynh/data/simpsonsvqa/v1_Question_Train_simpsons_vqa.json', 'r') as file:\n",
    "    train_questions = json.load(file)[\"questions\"]\n",
    "train_questions = pd.DataFrame(train_questions)\n",
    "train_questions[\"question_type\"] = train_questions[\"question\"].apply(lambda x: question_type_dict[x])\n",
    "train_question_type_summary = train_questions['question_type'].value_counts().reset_index()\n",
    "train_question_type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2347e374-6b06-46d4-8065-0a45ba1e81cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>img_path</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>24255</td>\n",
       "      <td>is the monster awake?</td>\n",
       "      <td>S26/S26E06-13901.jpg</td>\n",
       "      <td>binary question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               question              img_path    question_type\n",
       "17587  24255  is the monster awake?  S26/S26E06-13901.jpg  binary question"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[train_questions[\"question_type\"] == \"binary question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object identification</td>\n",
       "      <td>30251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color</td>\n",
       "      <td>28782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location and spatial relations</td>\n",
       "      <td>20030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>counting</td>\n",
       "      <td>13501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activity recognition</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>text and symbolism recognition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>health</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>time and sequence (for asking about the buss s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hairstyle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>condition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question_type  count\n",
       "0                               object identification  30251\n",
       "1                                               color  28782\n",
       "2                      location and spatial relations  20030\n",
       "3                                            counting  13501\n",
       "4                                activity recognition   6410\n",
       "..                                                ...    ...\n",
       "57                     text and symbolism recognition      1\n",
       "58                                             health      1\n",
       "59  time and sequence (for asking about the buss s...      1\n",
       "60                                          hairstyle      1\n",
       "61                                          condition      1\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04cf78fe-8e8f-4e88-9315-f4de368e4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))  # Set the figure size\n",
    "# plt.pie(train_question_type_summary['count'], labels=train_question_type_summary['question_type'], autopct='%1.1f%%', startangle=90, labeldistance=1.1, rotatelabels=True)\n",
    "# plt.title('Pie Chart Example', y=1.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fccca7-bc4d-40a8-ac51-a881f85d4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ndhuynh/data/simpsonsvqa/v1_Question_Val_simpsons_vqa.json', 'r') as file:\n",
    "    val_questions = json.load(file)[\"questions\"]\n",
    "val_questions = pd.DataFrame(val_questions)\n",
    "val_questions[\"question_type\"] = val_questions[\"question\"].apply(lambda x: question_type_dict[x])\n",
    "val_questions['question_type'].value_counts()\n",
    "val_question_type_summary = val_questions['question_type'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cccb716-9a81-4e2e-9eab-ac2edadba6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))  # Set the figure size\n",
    "# plt.pie(val_question_type_summary['count'], labels=val_question_type_summary['question_type'], autopct='%1.1f%%', startangle=90, labeldistance=1.1, rotatelabels=True)\n",
    "# plt.title('Pie Chart Example', y=1.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8d6f4-af2b-496e-82e8-c9fb8969d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
