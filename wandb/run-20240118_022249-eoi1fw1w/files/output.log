sample number: 96169
output_dim: 8
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
sample number: 18473
output_dim: 8
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): BertForSequenceClassification(
      (bert): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): Embedding(30522, 768, padding_idx=0)
            )
          )
          (position_embeddings): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): Embedding(512, 768)
            )
          )
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): BertEncoder(
              (layer): ModuleList(
                (0): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (1): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (2): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (3): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (4): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (5): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (6): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (7): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (8): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (9): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (10): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (11): BertLayer(
                  (attention): BertAttention(
                    (self): BertSelfAttention(
                      (query): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (key): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (value): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                    (output): BertSelfOutput(
                      (dense): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): FlattenParamsWrapper(
                          (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
                        )
                      )
                      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                      (dropout): Dropout(p=0.1, inplace=False)
                    )
                  )
                  (intermediate): BertIntermediate(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=768, out_features=3072, bias=True)
                      )
                    )
                    (intermediate_act_fn): GELUActivation()
                  )
                  (output): BertOutput(
                    (dense): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=3072, out_features=768, bias=True)
                      )
                    )
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): Linear(in_features=768, out_features=768, bias=True)
            )
          )
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): Linear(in_features=768, out_features=8, bias=True)
    )
  )
)
/home/ndhuynh/.conda/envs/hie/lib/python3.9/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f57a9b1e820>
Traceback (most recent call last):
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1510, in __del__
    self._shutdown_workers()
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1474, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ndhuynh/.conda/envs/hie/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 71, in _wrap
    pass  # SIGINT; Killed by parent, do nothing
KeyboardInterrupt