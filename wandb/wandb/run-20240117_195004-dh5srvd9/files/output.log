sample number: 96169
output_dim: 8
token_size: 7057
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
sample number: 18473
output_dim: 8
token_size: 7057
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
[[ 0.48409   0.33505   0.42066  ... -1.7047   -0.62474   0.69989 ]
 [ 0.14354   0.057574  0.070036 ... -0.057567 -0.037463  0.060437]
 [-7.1395   -2.4339   -2.5181   ... -4.8147   -5.1779    6.7697  ]
 ...
 [ 3.9665   -0.4368   -4.9797   ...  1.2008   -2.9568    2.8831  ]
 [-1.0742    0.28313  -1.0317   ...  2.0254   -1.347     0.38743 ]
 [ 1.2023   -1.0608   -0.7661   ...  2.0222    2.6343    3.7644  ]]
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): Net(
      (word_embeddings): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Embedding(7057, 300)
        )
      )
      (question_encoder): QuestionEmbedding(
        (lstm): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LSTM(300, 1024, batch_first=True)
          )
        )
        (fc): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=1024, out_features=1024, bias=True)
          )
        )
      )
      (qt_header): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=1024, out_features=1000, bias=True)
          )
        )
        (1): Dropout(p=0.5, inplace=False)
        (2): Tanh()
        (3): Linear(in_features=1000, out_features=8, bias=True)
      )
    )
  )
)
Train Epoch: 1 	Loss: 1.995206
Test set: Average loss: 1.8924, Accuracy: 5014/18474 (27.14%)
Train Epoch: 2 	Loss: 1.794740
Test set: Average loss: 1.7412, Accuracy: 5012/18474 (27.13%)
Train Epoch: 3 	Loss: 1.699548
Test set: Average loss: 1.7247, Accuracy: 5015/18474 (27.15%)
Train Epoch: 4 	Loss: 1.689402
Test set: Average loss: 1.7224, Accuracy: 5021/18474 (27.18%)
Train Epoch: 5 	Loss: 1.686768
Test set: Average loss: 1.7220, Accuracy: 5015/18474 (27.15%)
Train Epoch: 6 	Loss: 1.688027
Test set: Average loss: 1.7213, Accuracy: 5015/18474 (27.15%)
Train Epoch: 7 	Loss: 1.687078
Test set: Average loss: 1.7213, Accuracy: 5015/18474 (27.15%)
Train Epoch: 8 	Loss: 1.686606
Test set: Average loss: 1.7217, Accuracy: 5016/18474 (27.15%)
Train Epoch: 9 	Loss: 1.686544
Test set: Average loss: 1.7200, Accuracy: 5057/18474 (27.37%)
Train Epoch: 10 	Loss: 1.682019
Test set: Average loss: 1.7142, Accuracy: 5799/18474 (31.39%)
Train Epoch: 11 	Loss: 1.665525
Test set: Average loss: 1.6722, Accuracy: 8960/18474 (48.50%)
Train Epoch: 12 	Loss: 1.555399
Test set: Average loss: 1.4148, Accuracy: 9242/18474 (50.03%)
Train Epoch: 13 	Loss: 1.202459
Test set: Average loss: 1.0903, Accuracy: 11878/18474 (64.30%)
Train Epoch: 14 	Loss: 0.952639
Test set: Average loss: 0.9047, Accuracy: 12678/18474 (68.63%)
Train Epoch: 15 	Loss: 0.772397
Test set: Average loss: 0.6927, Accuracy: 13581/18474 (73.51%)
Train Epoch: 16 	Loss: 0.569629
Test set: Average loss: 0.5120, Accuracy: 16385/18474 (88.69%)
Train Epoch: 17 	Loss: 0.434350
Test set: Average loss: 0.4359, Accuracy: 16568/18474 (89.68%)
Train Epoch: 18 	Loss: 0.373799
Test set: Average loss: 0.3964, Accuracy: 16627/18474 (90.00%)
Train Epoch: 19 	Loss: 0.340603
Test set: Average loss: 0.3738, Accuracy: 16640/18474 (90.07%)
Train Epoch: 20 	Loss: 0.321670
Test set: Average loss: 0.3556, Accuracy: 16662/18474 (90.19%)
Train Epoch: 21 	Loss: 0.300336
Test set: Average loss: 0.3396, Accuracy: 16749/18474 (90.66%)
Train Epoch: 22 	Loss: 0.291259
Test set: Average loss: 0.3344, Accuracy: 16765/18474 (90.75%)
Train Epoch: 23 	Loss: 0.279464
Test set: Average loss: 0.3368, Accuracy: 16773/18474 (90.79%)
Train Epoch: 24 	Loss: 0.268513
Test set: Average loss: 0.3131, Accuracy: 16900/18474 (91.48%)
Train Epoch: 25 	Loss: 0.258947
Test set: Average loss: 0.3066, Accuracy: 16943/18474 (91.71%)
Train Epoch: 26 	Loss: 0.254675
Test set: Average loss: 0.3062, Accuracy: 16934/18474 (91.66%)
Train Epoch: 27 	Loss: 0.249570
Test set: Average loss: 0.2969, Accuracy: 16969/18474 (91.85%)
Train Epoch: 28 	Loss: 0.244237
Test set: Average loss: 0.2939, Accuracy: 16983/18474 (91.93%)
Train Epoch: 29 	Loss: 0.240679
Test set: Average loss: 0.2900, Accuracy: 16990/18474 (91.97%)
Train Epoch: 30 	Loss: 0.234911
Test set: Average loss: 0.2876, Accuracy: 17015/18474 (92.10%)
Train Epoch: 31 	Loss: 0.234085
Test set: Average loss: 0.2956, Accuracy: 17000/18474 (92.02%)
Train Epoch: 32 	Loss: 0.225586
Test set: Average loss: 0.2781, Accuracy: 17030/18474 (92.18%)
Train Epoch: 33 	Loss: 0.226381
Test set: Average loss: 0.2742, Accuracy: 17038/18474 (92.23%)
Train Epoch: 34 	Loss: 0.219629
Test set: Average loss: 0.2719, Accuracy: 17036/18474 (92.22%)
Train Epoch: 35 	Loss: 0.217778
Test set: Average loss: 0.2697, Accuracy: 17056/18474 (92.32%)
Train Epoch: 36 	Loss: 0.213035
Test set: Average loss: 0.2721, Accuracy: 17084/18474 (92.48%)
Train Epoch: 37 	Loss: 0.211119
Test set: Average loss: 0.2710, Accuracy: 17100/18474 (92.56%)
Train Epoch: 38 	Loss: 0.207890
Test set: Average loss: 0.2655, Accuracy: 17137/18474 (92.76%)
Train Epoch: 39 	Loss: 0.205095
Test set: Average loss: 0.2604, Accuracy: 17127/18474 (92.71%)
Train Epoch: 40 	Loss: 0.201879
Test set: Average loss: 0.2581, Accuracy: 17153/18474 (92.85%)
Train Epoch: 41 	Loss: 0.198346
Test set: Average loss: 0.2567, Accuracy: 17147/18474 (92.82%)
Train Epoch: 42 	Loss: 0.195770
Test set: Average loss: 0.2615, Accuracy: 17194/18474 (93.07%)
Train Epoch: 43 	Loss: 0.192854
Test set: Average loss: 0.2521, Accuracy: 17200/18474 (93.10%)
Train Epoch: 44 	Loss: 0.189509
Test set: Average loss: 0.2528, Accuracy: 17173/18474 (92.96%)
Train Epoch: 45 	Loss: 0.189122
Test set: Average loss: 0.2474, Accuracy: 17214/18474 (93.18%)
Train Epoch: 46 	Loss: 0.184334
Test set: Average loss: 0.2464, Accuracy: 17225/18474 (93.24%)
Train Epoch: 47 	Loss: 0.185595
Test set: Average loss: 0.2463, Accuracy: 17233/18474 (93.28%)
Train Epoch: 48 	Loss: 0.180764
Test set: Average loss: 0.2525, Accuracy: 17244/18474 (93.34%)
Train Epoch: 49 	Loss: 0.181452
Test set: Average loss: 0.2439, Accuracy: 17244/18474 (93.34%)
Train Epoch: 50 	Loss: 0.173650
Test set: Average loss: 0.2435, Accuracy: 17250/18474 (93.37%)
CUDA event elapsed time: 8571.771sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): Net(
      (word_embeddings): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Embedding(7057, 300)
        )
      )
      (question_encoder): QuestionEmbedding(
        (lstm): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LSTM(300, 1024, batch_first=True)
          )
        )
        (fc): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=1024, out_features=1024, bias=True)
          )
        )
      )
      (qt_header): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=1024, out_features=1000, bias=True)
          )
        )
        (1): Dropout(p=0.5, inplace=False)
        (2): Tanh()
        (3): Linear(in_features=1000, out_features=8, bias=True)
      )
    )
  )
)