sample number: 96169
output_dim: 8
token_size: 7057
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
sample number: 18473
output_dim: 8
token_size: 7057
ans_type_to_idx: {'yes/no': 0, 'action': 1, 'object': 2, 'location': 3, 'other': 4, 'color': 5, 'human': 6, 'number': 7}
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): Net(
      (word_embeddings): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Embedding(7057, 300)
        )
      )
      (question_encoder): QuestionEmbedding(
        (lstm): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LSTM(300, 1024, num_layers=2, batch_first=True, bidirectional=True)
          )
        )
        (fc): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=2048, out_features=1024, bias=True)
          )
        )
      )
      (qt_header): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=1024, out_features=1000, bias=True)
          )
        )
        (1): Dropout(p=0.5, inplace=False)
        (2): Tanh()
        (3): Linear(in_features=1000, out_features=8, bias=True)
      )
    )
  )
)
/home/ndhuynh/.conda/envs/hie/lib/python3.9/site-packages/torch/nn/modules/rnn.py:769: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/cudnn/RNN.cpp:968.)
  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
Train Epoch: 1 	Loss: 2.005605
Test set: Average loss: 1.9021, Accuracy: 8557/18474 (46.32%)
Train Epoch: 2 	Loss: 1.757631
Test set: Average loss: 1.6780, Accuracy: 9638/18474 (52.17%)
Train Epoch: 3 	Loss: 1.586566
Test set: Average loss: 1.5191, Accuracy: 9635/18474 (52.15%)
Train Epoch: 4 	Loss: 1.367283
Test set: Average loss: 1.1884, Accuracy: 9715/18474 (52.59%)
Train Epoch: 5 	Loss: 0.990173
Test set: Average loss: 0.8154, Accuracy: 14908/18474 (80.70%)
Train Epoch: 6 	Loss: 0.716893
Test set: Average loss: 0.6541, Accuracy: 15148/18474 (82.00%)
Train Epoch: 7 	Loss: 0.601158
Test set: Average loss: 0.5999, Accuracy: 15217/18474 (82.37%)
Train Epoch: 8 	Loss: 0.544134
Test set: Average loss: 0.5544, Accuracy: 15606/18474 (84.48%)
Train Epoch: 9 	Loss: 0.493386
Test set: Average loss: 0.5077, Accuracy: 16268/18474 (88.06%)
Train Epoch: 10 	Loss: 0.450591
Test set: Average loss: 0.4888, Accuracy: 16383/18474 (88.68%)
Train Epoch: 11 	Loss: 0.412262
Test set: Average loss: 0.4545, Accuracy: 16451/18474 (89.05%)
Train Epoch: 12 	Loss: 0.393317
Test set: Average loss: 0.4250, Accuracy: 16488/18474 (89.25%)
Train Epoch: 13 	Loss: 0.375863
Test set: Average loss: 0.4083, Accuracy: 16508/18474 (89.36%)
Train Epoch: 14 	Loss: 0.362371
Test set: Average loss: 0.3974, Accuracy: 16528/18474 (89.47%)
Train Epoch: 15 	Loss: 0.345324
Test set: Average loss: 0.3903, Accuracy: 16529/18474 (89.47%)
Train Epoch: 16 	Loss: 0.341591
Test set: Average loss: 0.3901, Accuracy: 16560/18474 (89.64%)
Train Epoch: 17 	Loss: 0.329856
Test set: Average loss: 0.3713, Accuracy: 16561/18474 (89.64%)
Train Epoch: 18 	Loss: 0.321584
Test set: Average loss: 0.3727, Accuracy: 16597/18474 (89.84%)
Train Epoch: 19 	Loss: 0.316873
Test set: Average loss: 0.3708, Accuracy: 16586/18474 (89.78%)
Train Epoch: 20 	Loss: 0.311398
Test set: Average loss: 0.3590, Accuracy: 16615/18474 (89.94%)
Train Epoch: 21 	Loss: 0.303123
Test set: Average loss: 0.3553, Accuracy: 16625/18474 (89.99%)
Train Epoch: 22 	Loss: 0.300036
Test set: Average loss: 0.3464, Accuracy: 16644/18474 (90.09%)
Train Epoch: 23 	Loss: 0.296740
Test set: Average loss: 0.3502, Accuracy: 16579/18474 (89.74%)
Train Epoch: 24 	Loss: 0.293912
Test set: Average loss: 0.3395, Accuracy: 16642/18474 (90.08%)
Train Epoch: 25 	Loss: 0.285381
Test set: Average loss: 0.3450, Accuracy: 16604/18474 (89.88%)
Train Epoch: 26 	Loss: 0.286683
Test set: Average loss: 0.3503, Accuracy: 16667/18474 (90.22%)
Train Epoch: 27 	Loss: 0.278427
Test set: Average loss: 0.3356, Accuracy: 16682/18474 (90.30%)
Train Epoch: 28 	Loss: 0.278817
Test set: Average loss: 0.3346, Accuracy: 16666/18474 (90.21%)
Train Epoch: 29 	Loss: 0.270740
Test set: Average loss: 0.3278, Accuracy: 16700/18474 (90.40%)
Train Epoch: 30 	Loss: 0.270204
Test set: Average loss: 0.3216, Accuracy: 16739/18474 (90.61%)
Train Epoch: 31 	Loss: 0.266931
Test set: Average loss: 0.3270, Accuracy: 16711/18474 (90.46%)
Train Epoch: 32 	Loss: 0.261068
Test set: Average loss: 0.3166, Accuracy: 16724/18474 (90.53%)
Train Epoch: 33 	Loss: 0.262309
Test set: Average loss: 0.3154, Accuracy: 16759/18474 (90.72%)
Train Epoch: 34 	Loss: 0.256909
Test set: Average loss: 0.3168, Accuracy: 16776/18474 (90.81%)
Train Epoch: 35 	Loss: 0.255810
Test set: Average loss: 0.3080, Accuracy: 16827/18474 (91.08%)
Train Epoch: 36 	Loss: 0.258775
Test set: Average loss: 0.3344, Accuracy: 16753/18474 (90.68%)
Train Epoch: 37 	Loss: 0.247154
Test set: Average loss: 0.3066, Accuracy: 16846/18474 (91.19%)
Train Epoch: 38 	Loss: 0.249438
Test set: Average loss: 0.3115, Accuracy: 16845/18474 (91.18%)
Train Epoch: 39 	Loss: 0.246420
Test set: Average loss: 0.3277, Accuracy: 16790/18474 (90.88%)
Train Epoch: 40 	Loss: 0.246976
Test set: Average loss: 0.3086, Accuracy: 16846/18474 (91.19%)
Train Epoch: 41 	Loss: 0.244038
Test set: Average loss: 0.2992, Accuracy: 16874/18474 (91.34%)
Train Epoch: 42 	Loss: 0.242488
Test set: Average loss: 0.2958, Accuracy: 16849/18474 (91.20%)
Train Epoch: 43 	Loss: 0.240488
Test set: Average loss: 0.2961, Accuracy: 16916/18474 (91.57%)
Train Epoch: 44 	Loss: 0.233564
Test set: Average loss: 0.2936, Accuracy: 16920/18474 (91.59%)