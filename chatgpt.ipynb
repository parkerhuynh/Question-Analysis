{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50929]  to question_type_gpt.json\n",
      "[2/50929]  to question_type_gpt.json\n",
      "[3/50929]  to question_type_gpt.json\n",
      "[4/50929]  to question_type_gpt.json\n",
      "[5/50929]  to question_type_gpt.json\n",
      "[6/50929]  to question_type_gpt.json\n",
      "[7/50929]  to question_type_gpt.json\n",
      "[8/50929]  to question_type_gpt.json\n",
      "[9/50929]  to question_type_gpt.json\n",
      "[10/50929]  to question_type_gpt.json\n",
      "[11/50929]  to question_type_gpt.json\n",
      "[12/50929]  to question_type_gpt.json\n",
      "[13/50929]  to question_type_gpt.json\n",
      "[14/50929]  to question_type_gpt.json\n",
      "[15/50929]  to question_type_gpt.json\n",
      "[16/50929]  to question_type_gpt.json\n",
      "[17/50929]  to question_type_gpt.json\n",
      "[18/50929]  to question_type_gpt.json\n",
      "[19/50929]  to question_type_gpt.json\n",
      "[20/50929]  to question_type_gpt.json\n",
      "[21/50929]  to question_type_gpt.json\n",
      "[22/50929]  to question_type_gpt.json\n",
      "[23/50929]  to question_type_gpt.json\n",
      "[24/50929]  to question_type_gpt.json\n",
      "[25/50929]  to question_type_gpt.json\n",
      "[26/50929]  to question_type_gpt.json\n",
      "[27/50929]  to question_type_gpt.json\n",
      "[28/50929]  to question_type_gpt.json\n",
      "[29/50929]  to question_type_gpt.json\n",
      "[30/50929]  to question_type_gpt.json\n",
      "[31/50929]  to question_type_gpt.json\n",
      "[32/50929]  to question_type_gpt.json\n",
      "[33/50929]  to question_type_gpt.json\n",
      "[34/50929]  to question_type_gpt.json\n",
      "[35/50929]  to question_type_gpt.json\n",
      "[36/50929]  to question_type_gpt.json\n",
      "[37/50929]  to question_type_gpt.json\n",
      "[38/50929]  to question_type_gpt.json\n",
      "[39/50929]  to question_type_gpt.json\n",
      "[40/50929]  to question_type_gpt.json\n",
      "[41/50929]  to question_type_gpt.json\n",
      "[42/50929]  to question_type_gpt.json\n",
      "[43/50929]  to question_type_gpt.json\n",
      "[44/50929]  to question_type_gpt.json\n",
      "[45/50929]  to question_type_gpt.json\n",
      "[46/50929]  to question_type_gpt.json\n",
      "[47/50929]  to question_type_gpt.json\n",
      "[48/50929]  to question_type_gpt.json\n",
      "[49/50929]  to question_type_gpt.json\n",
      "[50/50929]  to question_type_gpt.json\n",
      "[51/50929]  to question_type_gpt.json\n",
      "[52/50929]  to question_type_gpt.json\n",
      "[53/50929]  to question_type_gpt.json\n",
      "[54/50929]  to question_type_gpt.json\n",
      "[55/50929]  to question_type_gpt.json\n",
      "[56/50929]  to question_type_gpt.json\n",
      "[57/50929]  to question_type_gpt.json\n",
      "[58/50929]  to question_type_gpt.json\n",
      "[59/50929]  to question_type_gpt.json\n",
      "[60/50929]  to question_type_gpt.json\n",
      "[61/50929]  to question_type_gpt.json\n",
      "[62/50929]  to question_type_gpt.json\n",
      "[63/50929]  to question_type_gpt.json\n",
      "[64/50929]  to question_type_gpt.json\n",
      "[65/50929]  to question_type_gpt.json\n",
      "[66/50929]  to question_type_gpt.json\n",
      "[67/50929]  to question_type_gpt.json\n",
      "[68/50929]  to question_type_gpt.json\n",
      "[69/50929]  to question_type_gpt.json\n",
      "[70/50929]  to question_type_gpt.json\n",
      "[71/50929]  to question_type_gpt.json\n",
      "[72/50929]  to question_type_gpt.json\n",
      "[73/50929]  to question_type_gpt.json\n",
      "[74/50929]  to question_type_gpt.json\n",
      "[75/50929]  to question_type_gpt.json\n",
      "[76/50929]  to question_type_gpt.json\n",
      "[77/50929]  to question_type_gpt.json\n",
      "[78/50929]  to question_type_gpt.json\n",
      "[79/50929]  to question_type_gpt.json\n",
      "[80/50929]  to question_type_gpt.json\n",
      "[81/50929]  to question_type_gpt.json\n",
      "[82/50929]  to question_type_gpt.json\n",
      "[83/50929]  to question_type_gpt.json\n",
      "[84/50929]  to question_type_gpt.json\n",
      "[85/50929]  to question_type_gpt.json\n",
      "[86/50929]  to question_type_gpt.json\n",
      "[87/50929]  to question_type_gpt.json\n",
      "[88/50929]  to question_type_gpt.json\n",
      "[89/50929]  to question_type_gpt.json\n",
      "[90/50929]  to question_type_gpt.json\n",
      "[91/50929]  to question_type_gpt.json\n",
      "[92/50929]  to question_type_gpt.json\n",
      "[93/50929]  to question_type_gpt.json\n",
      "[94/50929]  to question_type_gpt.json\n",
      "[95/50929]  to question_type_gpt.json\n",
      "[96/50929]  to question_type_gpt.json\n",
      "[97/50929]  to question_type_gpt.json\n",
      "[98/50929]  to question_type_gpt.json\n",
      "[99/50929]  to question_type_gpt.json\n",
      "[100/50929]  to question_type_gpt.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "\n",
    "with open('/home/ndhuynh/openai.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        openKey = line\n",
    "        \n",
    "def categorize_question(question_input, openKey):\n",
    "    content = f\"\"\"Please categorize the following questions into ONE of the provided question types: \n",
    "    'yes/no', 'object identification', 'activity recognition', 'sport identification',\n",
    "    'color', 'shape', 'counting', 'location and spatial relations', 'time and sequence', 'person identification',\n",
    "    'text and signage recognition', 'emotion and sentiment', 'comparison', 'weather', 'animal'.\n",
    "\n",
    "    Question: What color are the clouds?\n",
    "    Question Type: color,\n",
    "    Question: Is there a building in the background?\n",
    "    Question Type: yes/no,\n",
    "    Question: Are all the bartenders dressed in the same outfit?\n",
    "    Question Type: yes/no,\n",
    "    Question: {question_input}\n",
    "    Question Type:\n",
    "    \"\"\"\n",
    "    client = OpenAI( api_key=openKey)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    response = response.choices[0].message.content\n",
    "    # Extract the Question Type from the response\n",
    "    question_type = response.split(\"Question Type: \")[-1].strip()\n",
    "    \n",
    "    return question_type\n",
    "\n",
    "question_paths = [\n",
    "    \"/home/ndhuynh/data/simpsonsvqa/v1_Question_Train_simpsons_vqa.json\",\n",
    "    \"/home/ndhuynh/data/simpsonsvqa/v1_Question_Val_simpsons_vqa.json\"\n",
    "    ]\n",
    "\n",
    "question_list = []\n",
    "for ques_path in question_paths:\n",
    "    with open(ques_path, 'r') as file:\n",
    "        questions = json.load(file)[\"questions\"]\n",
    "        question_list += questions\n",
    "question_df = pd.DataFrame(question_list)\n",
    "\n",
    "question_unique_list = question_df[\"question\"].unique()\n",
    "\n",
    "for i in range(100):\n",
    "    question_str = question_unique_list[i]\n",
    "    chatgpt_question_type = categorize_question(question_str, openKey)\n",
    "\n",
    "    # Create a dictionary with the current key-value pair\n",
    "    data = {question_str: chatgpt_question_type}\n",
    "\n",
    "    # Specify the file name where you want to save the JSON data\n",
    "    file_name = \"question_type_gpt.json\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Open the file in append mode and save the current item to it in JSON format\n",
    "            with open(file_name, 'a') as json_file:\n",
    "                json.dump(data, json_file)\n",
    "                json_file.write('\\n')  # Add a newline to separate each item\n",
    "\n",
    "            print(f'[{i + 1}/{len(question_unique_list)}]  to {file_name}')\n",
    "            break  # Exit the retry loop if successful\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            print('Retrying...')\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
